{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e40e46b",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0ff1eb0",
   "metadata": {},
   "source": [
    "### Spark Cluster\n",
    "![img](./data/iShot_2023-03-17_10.26.09.png)  \n",
    "1. Hadoop 등에서 채용하고 있는 전형적인 Cluster & Mater/Slave 구조\n",
    "1. Cluster Manager\n",
    "    * stand alone, hadoop yarn, 메소스\n",
    "1. Master\n",
    "    * Driver program\n",
    "1. Slave(Worker)\n",
    "    * Executor\n",
    "        * Task 수행\n",
    "        * Data 캐싱\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c97c619c",
   "metadata": {},
   "source": [
    "### Spark 에서 사용 가능한 언어\n",
    "* Scala\n",
    "* Java\n",
    "* Python\n",
    "* SQL\n",
    "* R\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5b34450",
   "metadata": {},
   "source": [
    "### Spark Shell & Spark App\n",
    "1. Spark 구동 방법\n",
    "    * Shell(대화형) or App\n",
    "1. Shell(대화형)\n",
    "    * 터미널을 이용하여 spark master 에 명령을 전달, 이를 수행\n",
    "    * shell 에서 spark context를 자체 생성\n",
    "1. App\n",
    "    * Spark Context를 생성 후 명령을 실행\n",
    "    * Spark Submit 프로그램을 통해 jar 파일 실행\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01b42ba8",
   "metadata": {},
   "source": [
    "### SparkSession\n",
    "SparkSession 인스턴스는 사용자가 정의한 처리 명령을 클러스터에 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d274b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ken/Project/spark/spark'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56fa8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read S3 Parquet\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe55174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ken:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Read S3 Parquet</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd4f8637eb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SparkContext 내용 확인\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e813db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ex\n",
    "# spark 분산 환경에서 아래 1000개의 row 는 각각 다른 executor 에 할당되어 필요한 작업 수행\n",
    "myRange = spark.range(1000).toDF(\"number\")\n",
    "myRange.show(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "797c5de6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### DataFrame\n",
    "* DataFrame은 테이블 형태와 동일\n",
    "* 일반 테이블과 다른 점은 DataFrame은 다수의 서버에 분산 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f6572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Alice| 25|\n",
      "|    Bob| 30|\n",
      "|Charlie| 35|\n",
      "|  David| 40|\n",
      "+-------+---+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n",
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|  Alice|\n",
      "|    Bob|\n",
      "|Charlie|\n",
      "|  David|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ex\n",
    "# 데이터 생성 및 DataFrame 생성\n",
    "data = [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 35), (\"David\", 40)]\n",
    "df = spark.createDataFrame(data, [\"name\", \"age\"])\n",
    "# DataFrame 출력\n",
    "df.show()\n",
    "# DataFrame의 스키마 출력\n",
    "df.printSchema()\n",
    "# DataFrame의 특정 컬럼 선택\n",
    "df.select(\"name\").show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cdf2541",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Transformation\n",
    "\n",
    "1. narrow dependency\n",
    "    * fitler 등\n",
    "    * 각 파티션 내에서 이루어 지는 작업\n",
    "    * 파티션 간 영향을 주지 않음\n",
    "1. wide dependency\n",
    "    * grouping, sorting 등\n",
    "    * 파티션 간 데이터를 교환이 필요한 작업\n",
    "    * 셔플링이 발생 (성능 저하)\n",
    "1. lazy evaluation\n",
    "    * spark 의 장점 중 하나\n",
    "    * 각 단계마다 작업을 수행하지 않음\n",
    "    * 실행 계획 수립 후 최적화 진행"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09152378",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Spark 간단하게 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8022c64-43ed-4418-8bf8-a3ab690f18c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ken/Project/spark/spark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41ef3ba-aa4a-49b4-8ced-7c13c80fbf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/17 10:19:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read S3 Parquet\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c83931-9116-4475-a3d4-186df30f952b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_order = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"data/order.parquet\")\n",
    "\n",
    "df_custom = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"data/custom.parquet\")\n",
    "\n",
    "df_product = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"data/product.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c220aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+------------------+------+-------------+------------------+-----+-------------------------+\n",
      "|summary|  Op|     dms_update_time|                id|  name| phone_number|               age|  sex|                  address|\n",
      "+-------+----+--------------------+------------------+------+-------------+------------------+-----+-------------------------+\n",
      "|  count| 100|                 100|               100|   100|          100|               100|  100|                      100|\n",
      "|   mean|null|                null|              50.5|  null|         null|             38.99| null|                     null|\n",
      "| stddev|null|                null|29.011491975882016|  null|         null|12.109346085824066| null|                     null|\n",
      "|    min|   I|2023-03-11 07:58:...|                 1|강순자|010-5187-4041|                20|  man| 강원도 고양시 서초중앙길|\n",
      "|    max|   I|2023-03-11 07:58:...|               100|황진호|070-2143-5674|                59|woman|충청북도 안양시 역삼523로|\n",
      "+-------+----+--------------------+------------------+------+-------------+------------------+-----+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_custom.printSchema()\n",
    "# df_custom.show()\n",
    "df_custom.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_product.printSchema()\n",
    "# df_product.show()\n",
    "# df_product.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "077c21e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------------------+-----------------+-----------------+------------------+----------------+------------------+----------+\n",
      "|summary|   Op|     dms_update_time|               id|          cust_id|            prd_id|       order_cnt|       order_price|  order_dt|\n",
      "+-------+-----+--------------------+-----------------+-----------------+------------------+----------------+------------------+----------+\n",
      "|  count|20000|               20000|            20000|            20000|             20000|           20000|             20000|     20000|\n",
      "|   mean| null|                null|          10000.5|          50.0301|          49.80605|          2.5011|       51463.80045|      null|\n",
      "| stddev| null|                null|5773.647027659381|28.43825998055321|28.795082761420648|1.11196250522697|28319.863064266883|      null|\n",
      "|    min|    I|2023-03-11 07:58:...|                1|                1|                 1|               1|             10000|2023-03-01|\n",
      "|    max|    I|2023-03-11 07:58:...|            20000|               99|                99|               4|             99000|2023-03-11|\n",
      "+-------+-----+--------------------+-----------------+-----------------+------------------+----------------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_order.printSchema()\n",
    "# df_order.show()\n",
    "df_order.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d0d5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom.createOrReplaceTempView(\"custom\")\n",
    "df_order.createOrReplaceTempView(\"orders\")\n",
    "df_product.createOrReplaceTempView(\"product\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57d7c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023년 판매 내역\n",
    "sql1 = \"\"\"\n",
    "SELECT c.name, c.age, p.name AS product_name, o.order_cnt, o.order_price\n",
    "FROM custom c\n",
    "JOIN orders o ON c.id = o.cust_id\n",
    "JOIN product p ON p.id = o.prd_id\n",
    "WHERE o.order_dt BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a3dcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고객별로 구매한 상품 수, 총 구매액, 최근 주문일\n",
    "sql2 = \"\"\"\n",
    "SELECT c.id AS customer_id, c.name AS customer_name, COUNT(DISTINCT o.prd_id) AS num_products_purchased, \n",
    "       SUM(o.order_price * o.order_cnt) AS total_purchase_amount, MAX(o.order_dt) AS last_order_date\n",
    "FROM custom c\n",
    "JOIN orders o ON c.id = o.cust_id\n",
    "JOIN product p ON o.prd_id = p.id\n",
    "GROUP BY c.id, c.name\n",
    "ORDER BY total_purchase_amount DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d9ddbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격이 가장 비싼 상품을 조회\n",
    "sql3 = \"\"\"\n",
    "SELECT name, price \n",
    "FROM product \n",
    "WHERE price = (SELECT MAX(price) FROM product)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edb0d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여자 고객들의 수와 남자 고객들의 수를 조회\n",
    "sql4 = \"\"\"\n",
    "SELECT sex, COUNT(*) AS num_customers\n",
    "FROM custom\n",
    "GROUP BY sex\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "995bdd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023년 1월부터 3월까지의 총 구매액을 계산\n",
    "sql5 = \"\"\"\n",
    "SELECT int(SUM(order_price * order_cnt)) AS total_purchase_amount\n",
    "FROM orders\n",
    "WHERE order_dt >= '2023-01-01' AND order_dt <= '2023-03-31'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0553c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 많이 주문한 상위 10개의 상품과 해당 상품을 주문한 고객의 정보를 조회\n",
    "sql6 = \"\"\"\n",
    "SELECT p.name AS product_name, \n",
    "       c.name AS customer_name, \n",
    "       c.phone_number, \n",
    "       c.age, \n",
    "       c.sex, \n",
    "       c.address,\n",
    "       o.order_cnt, \n",
    "       o.order_price, \n",
    "       o.order_dt\n",
    "FROM (\n",
    "  SELECT prd_id, SUM(order_cnt) AS total_cnt\n",
    "  FROM orders\n",
    "  GROUP BY prd_id\n",
    "  ORDER BY total_cnt DESC\n",
    "  LIMIT 10\n",
    ") AS t\n",
    "JOIN orders AS o ON t.prd_id = o.prd_id\n",
    "JOIN product AS p ON o.prd_id = p.id\n",
    "JOIN custom AS c ON o.cust_id = c.id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "836b7dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30대 이상의 고객들이 구매한 상품 중 가격이 10,000원 이상인 상품들을 구매한 총 금액이 높은 순서로 조회\n",
    "sql7 = \"\"\"\n",
    "SELECT c.name, p.name, SUM(o.order_cnt * p.price) as total_price\n",
    "FROM custom c\n",
    "JOIN orders o ON c.id = o.cust_id\n",
    "JOIN product p ON p.id = o.prd_id\n",
    "WHERE c.age > 30\n",
    "GROUP BY c.name, p.name\n",
    "HAVING SUM(o.order_cnt * p.price) > 10000\n",
    "ORDER BY total_price DESC;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "61efe2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-----------+\n",
      "|  name|        name|total_price|\n",
      "+------+------------+-----------+\n",
      "|김승현|차돌된장찌개|  1081000.0|\n",
      "|홍은주|        닭발|  1012000.0|\n",
      "|김민준|    부대찌개|   950000.0|\n",
      "|최현준|    마파두부|   880000.0|\n",
      "|김하은|  오므라이스|   840000.0|\n",
      "|김민준|      떡볶이|   828000.0|\n",
      "|한상철|    돼지갈비|   828000.0|\n",
      "|김경희|      팟타이|   816000.0|\n",
      "|이미영|      고로케|   805000.0|\n",
      "|전서현|    부대찌개|   800000.0|\n",
      "|이승현|    감자튀김|   800000.0|\n",
      "|안경숙|    초계국수|   800000.0|\n",
      "|김민준|      마카롱|   792000.0|\n",
      "|이준호|      어묵탕|   783000.0|\n",
      "|이지은|        닭발|   782000.0|\n",
      "|이준호|      토스트|   770000.0|\n",
      "|이상철|  아이스크림|   760000.0|\n",
      "|김민준|    샤브샤브|   752000.0|\n",
      "|남성훈|    크로와상|   752000.0|\n",
      "|김민준|차돌된장찌개|   752000.0|\n",
      "+------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql7).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03c165",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
